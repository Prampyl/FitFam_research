{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff75432",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afabab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "    from data_loader import FitFamDataLoader\n",
    "    print(\"Module data_loader importé avec succès.\")\n",
    "except ImportError:\n",
    "    print(\"ERREUR : Le fichier data_loader.py n'est pas trouvé dans le dossier.\")\n",
    "\n",
    "loader = FitFamDataLoader()\n",
    "unified_df = loader.get_unified_data()\n",
    "\n",
    "print(\"Données chargées.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc50fbe",
   "metadata": {},
   "source": [
    "## 2. Analyse par Année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_year(year):\n",
    "    print(f\"\\n--- Analyse pour l'année {year} ---\")\n",
    "    yearly_df = unified_df[unified_df['start_time'].dt.year == year]\n",
    "    yearly_df['date'] = yearly_df['start_time']\n",
    "    yearly_df = yearly_df.sort_values(['user_id', 'date'])\n",
    "\n",
    "    print(f\"Total lignes : {len(yearly_df)}\")\n",
    "    print(f\"Total utilisateurs : {yearly_df['user_id'].nunique()}\")\n",
    "    print(f\"Période : du {yearly_df['date'].min()} au {yearly_df['date'].max()}\")\n",
    "\n",
    "    # Feature Engineering\n",
    "    user_start = yearly_df.groupby('user_id')['date'].min().reset_index()\n",
    "    user_start.columns = ['user_id', 'start_date']\n",
    "    df = yearly_df.merge(user_start, on='user_id')\n",
    "\n",
    "    df['days_since_start'] = (df['date'] - df['start_date']).dt.days\n",
    "\n",
    "    max_date = df['date'].max()\n",
    "    cutoff_date = max_date - timedelta(days=90)\n",
    "    valid_users = user_start[user_start['start_date'] <= cutoff_date]['user_id']\n",
    "    df_cohort = df[df['user_id'].isin(valid_users)].copy()\n",
    "\n",
    "    print(f\"Utilisateurs analysables (>90 jours d'ancienneté) : {df_cohort['user_id'].nunique()}\")\n",
    "\n",
    "    early_activity = df_cohort[df_cohort['days_since_start'] <= 14]\n",
    "\n",
    "    h1_data = early_activity.groupby('user_id').size().reset_index(name='frequency_14d')\n",
    "\n",
    "    active_after_90d = df_cohort[df_cohort['days_since_start'] > 90]['user_id'].unique()\n",
    "    h1_data['is_retained_3m'] = h1_data['user_id'].isin(active_after_90d).astype(int)\n",
    "\n",
    "    # Regularity Metrics\n",
    "    def calculate_category_diversity(x):\n",
    "        if len(x) == 0:\n",
    "            return np.nan\n",
    "        unique_cats = x.nunique()\n",
    "        total_sessions = len(x)\n",
    "        return unique_cats / total_sessions\n",
    "\n",
    "    category_reg = early_activity.groupby('user_id')['category_name'].agg(calculate_category_diversity).reset_index(name='category_regularity_14d')\n",
    "\n",
    "    def calculate_temporal_balance(x):\n",
    "        if len(x) == 0:\n",
    "            return np.nan\n",
    "        weekday_count = x.dt.weekday.lt(5).sum()\n",
    "        total = len(x)\n",
    "        if total == 0:\n",
    "            return np.nan\n",
    "        weekday_prop = weekday_count / total\n",
    "        return abs(weekday_prop - 0.5)\n",
    "\n",
    "    temporal_reg = early_activity.groupby('user_id')['date'].agg(calculate_temporal_balance).reset_index(name='temporal_regularity_14d')\n",
    "\n",
    "    h1_data = h1_data.merge(category_reg, on='user_id', how='left')\n",
    "    h1_data = h1_data.merge(temporal_reg, on='user_id', how='left')\n",
    "\n",
    "    print(\"Nouvelles métriques de régularité calculées.\")\n",
    "    display(h1_data.head())\n",
    "\n",
    "    # Statistical Analysis\n",
    "    valid_cat = h1_data.dropna(subset=['category_regularity_14d'])\n",
    "    group_retained_cat = valid_cat[valid_cat['is_retained_3m'] == 1]['category_regularity_14d']\n",
    "    group_churned_cat = valid_cat[valid_cat['is_retained_3m'] == 0]['category_regularity_14d']\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    stat, p_value_cat = mannwhitneyu(group_retained_cat, group_churned_cat, alternative='two-sided')\n",
    "\n",
    "    print(\"Test sur la régularité par catégorie (diversité) :\")\n",
    "    print(f\"P-value = {p_value_cat:.5f}\")\n",
    "\n",
    "    valid_temp = h1_data.dropna(subset=['temporal_regularity_14d'])\n",
    "    group_retained_temp = valid_temp[valid_temp['is_retained_3m'] == 1]['temporal_regularity_14d']\n",
    "    group_churned_temp = valid_temp[valid_temp['is_retained_3m'] == 0]['temporal_regularity_14d']\n",
    "\n",
    "    stat, p_value_temp = mannwhitneyu(group_retained_temp, group_churned_temp, alternative='two-sided')\n",
    "\n",
    "    print(\"Test sur la régularité temporelle :\")\n",
    "    print(f\"P-value = {p_value_temp:.5f}\")\n",
    "\n",
    "    # Save Results\n",
    "    h1_data.to_csv(f'h1_exploratory_results_{year}.csv', index=False)\n",
    "    print(f\"Résultats sauvegardés dans h1_exploratory_results_{year}.csv\")\n",
    "\n",
    "# Analyse pour chaque année\n",
    "for year in [2023, 2024, 2025]:\n",
    "    analyze_year(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
